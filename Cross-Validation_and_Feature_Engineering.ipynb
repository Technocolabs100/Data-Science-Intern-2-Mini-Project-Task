{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the following two cells before you begin.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, import the cleaned data set. Then, select the features from the DataFrame of the case study data.**\n",
    "    \n",
    "These features should be: `'LIMIT_BAL'`, `'EDUCATION'`, `'MARRIAGE'`, `'AGE'`, `'PAY_1'`, `'BILL_AMT1'`, `'BILL_AMT2'`, `'BILL_AMT3'`, `'BILL_AMT4'`, `'BILL_AMT5'`, `'BILL_AMT6'`, `'PAY_AMT1'`, `'PAY_AMT2'`, `'PAY_AMT3'`, `'PAY_AMT4'`, `'PAY_AMT5'`, AND `'PAY_AMT6'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "cleaned_data=pd.read_csv(\"https://raw.githubusercontent.com/jsneha1710/Data-Science-Intern-2-Mini-Project-Task/master/Task%201%20Data%20set/cleaned_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features list\n",
    "features=['LIMIT_BAL', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "X=cleaned_data[features]\n",
    "y=cleaned_data['default payment next month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Next, make a 80:20 train/test split using a random seed of 24.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Then, instantiate the `MinMaxScaler` to scale the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Next, instantiate a logistic regression model with the `saga` solver, L1 penalty, and set `max_iter` to 1,000 as we want the solver to have enough iterations to find a good solution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='saga',penalty='l1',max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Next, import the `Pipeline` class and create a `Pipeline` with the scaler and the logistic regression model, using the names `'scaler'` and `'model'` for the steps, respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline=Pipeline([('scaler',MinMaxScaler()),('model',LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Now, use the `get_params` method to view the parameters from each stage of the pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(memory=None,\n",
       "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use `get_params`\n",
    "pipeline.get_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the `set_params` method to change the the `model__C` parameter to 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View what `model__C` is set to currently\n",
    "pipeline.set_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=2.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change `model__C` to 2\n",
    "Pipeline(memory=None,\n",
    "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
    "                ('model',\n",
    "                 LogisticRegression(C=2.0, class_weight=None, dual=False,\n",
    "                                    fit_intercept=True, intercept_scaling=1,\n",
    "                                    l1_ratio=None, max_iter=100,\n",
    "                                    multi_class='warn', n_jobs=None,\n",
    "                                    penalty='l2', random_state=None,\n",
    "                                    solver='warn', tol=0.0001, verbose=0,\n",
    "                                    warm_start=False))],\n",
    "         verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=2.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.set_params(model__C=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Then, create a smaller range of C values to test with cross-validation, as these models will take longer to train and test with more data than our previous activities.**\n",
    "\n",
    "**Use C_vals = [$10^2$, $10$, $1$, $10^{-1}$, $10^{-2}$, $10^{-3}$].**\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Hint:</summary>\n",
    "    Recall that exponents in Python use the ** operator.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " C_vals = [ 10**2 ,  10 ,  1 , 10**-1 , 10**-2, 10**-3  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define `k_folds` using `StratifiedKFold`. The number of folds should be 4. Set the random state to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds=StratifiedKFold(n_splits=4,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Next, make a new version of the `cross_val_C_search` function, called `cross_val_C_search_pipe`. Instead of the model argument, this function will take a pipeline argument. The changes inside the function will be to set the `C` value using `set_params(model__C = <value you want to test>)` on the pipeline, replacing the model with the pipeline for the fit and `predict_proba` methods, and accessing the `C` value using `pipeline.get_params()['model__C']` for the printed status update.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_C_search_pipe(pipeline,vals):\n",
    "    pipeline.set_params(model__C=vals)\n",
    "    pipeline.get_params()\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Now, run this function as in the previous activity, but using the new range of `C` values, the pipeline you created, and the features and response variable from the training split of the case study data.**\n",
    "\n",
    "    You may see warnings here, or in later steps, about the non-convergence of the solver; you could experiment with the `tol` or `max_iter`` options to try and achieve convergence, although the results you obtain with `max_iter = 1000` are likely to be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 of KFold 4\n",
      "ROC AUC score: 0.6017674902186108\n",
      "100 of KFold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.6080197898851698\n",
      "100 of KFold 4\n",
      "ROC AUC score: 0.6189539774065206\n",
      "100 of KFold 4\n",
      "ROC AUC score: 0.6135945689103064\n",
      "10 of KFold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.6001915032895931\n",
      "10 of KFold 4\n",
      "ROC AUC score: 0.6071765918208113\n",
      "10 of KFold 4\n",
      "ROC AUC score: 0.6179204243464007\n",
      "10 of KFold 4\n",
      "ROC AUC score: 0.612204392821335\n",
      "1 of KFold 4\n",
      "ROC AUC score: 0.5944263946621648\n",
      "1 of KFold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.6012622849396689\n",
      "1 of KFold 4\n",
      "ROC AUC score: 0.6046223283394039\n",
      "1 of KFold 4\n",
      "ROC AUC score: 0.6052672408965203\n",
      "0.1 of KFold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.5358460712933731\n",
      "0.1 of KFold 4\n",
      "ROC AUC score: 0.5327357683850477\n",
      "0.1 of KFold 4\n",
      "ROC AUC score: 0.5356362214332241\n",
      "0.1 of KFold 4\n",
      "ROC AUC score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.5459315966682844\n",
      "0.01 of KFold 4\n",
      "ROC AUC score: 0.5002463468588274\n",
      "0.01 of KFold 4\n",
      "ROC AUC score: 0.5016129032258064\n",
      "0.01 of KFold 4\n",
      "ROC AUC score: 0.500647750590984\n",
      "0.01 of KFold 4\n",
      "ROC AUC score:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.5003458279572376\n",
      "0.001 of KFold 4\n",
      "ROC AUC score: 0.5\n",
      "0.001 of KFold 4\n",
      "ROC AUC score: 0.5\n",
      "0.001 of KFold 4\n",
      "ROC AUC score: 0.5\n",
      "0.001 of KFold 4\n",
      "ROC AUC score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sneha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_test_full =0\n",
    "cv_score =[]\n",
    "i=1\n",
    "for i in C_vals:\n",
    "    for train_index,test_index in k_folds.split(X_train,y_train):\n",
    "        print('{} of KFold {}'.format(i,k_folds.n_splits))\n",
    "        xtr,xvl = X.loc[train_index],X.loc[test_index]\n",
    "        ytr,yvl = y.loc[train_index],y.loc[test_index]\n",
    "        cross_val_C_search_pipe(pipeline,i)\n",
    "        pipeline.fit(xtr,ytr)\n",
    "        score = roc_auc_score(yvl,pipeline.predict(xvl))\n",
    "        print('ROC AUC score:',score)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Plot the average training and testing ROC AUC across folds, for each `np.log(C_vals)` value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.log(C_vals)\n",
    "hundred=np.array([ 0.6017674902186108, 0.6080197898851698,0.6189539774065206,0.6135945689103064])\n",
    "ten=np.array([0.6001915032895931,0.6071765918208113,0.6179204243464007,0.612204392821335])\n",
    "one=np.array([0.5944263946621648,0.6012622849396689,0.6046223283394039,0.6052672408965203])\n",
    "p1=np.array([0.5358460712933731,0.5327357683850477,0.5356362214332241,0.5459315966682844])\n",
    "p2=np.array([0.5002463468588274,0.5016129032258064,0.500647750590984,0.5003458279572376])\n",
    "p3=np.array([0.5,0.5,0.5,0.5])\n",
    "roc_p=[hundred.mean(),ten.mean(),one.mean(),p1.mean(),p2.mean(),p3.mean()]\n",
    "plt.plot(x,roc_p,marker='o')\n",
    "plt.xlabel(\"log(C)\")\n",
    "plt.ylabel(\"ROC AUC\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Up next, create interaction features for the case study data using scikit-learn's `PolynomialFeatures`. You should use 2 as the degree of polynomial features. Confirm that the number of new features makes sense.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-c375d1d89a25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minteraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minteraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1544\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1545\u001b[0m                 XP = np.empty((n_samples, self.n_output_features_),\n\u001b[1;32m-> 1546\u001b[1;33m                               dtype=X.dtype, order=self.order)\n\u001b[0m\u001b[0;32m   1547\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m                     \u001b[0mXP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "interaction=PolynomialFeatures(degree=2)\n",
    "d=interaction.fit_transform(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________\n",
    "**Finally, repeat the cross-validation procedure and observe the model performance now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the new features, make a 80:20 train/test split using a random seed of 24.**\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the cross_val_C_search_pipe() function using the new training data.\n",
    "# All other parameters should remain the same.\n",
    "# Note that this training may take a few minutes due to the larger number of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eid": "b4f5a"
   },
   "outputs": [],
   "source": [
    "# Plot the average training and testing ROC AUC across folds, for each C value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take a look at the above graph. Does the average cross-validation testing performance improve with the interaction features? Is regularization useful?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
